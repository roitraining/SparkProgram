{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day2-Labs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_H1eukfMZpL",
        "colab": {},
        "outputId": "ae56f1cc-d851-47af-a3f8-2041a97d531c"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/class')\n",
        "from initspark import *\n",
        "sc, spark, conf = initspark()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initializing pyspark\n",
            "pyspark initialized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ArgIK-HvMZpS"
      },
      "source": [
        "**LAB:** Use the regions and territories RDDs from the previous lab and convert them into DataFrames with meaningful schemas.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QeFTvJLeMZpT",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "regions = sc.textFile('hdfs://localhost:9000/regions')\n",
        "regions = regions.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1]))\n",
        "regionsdf = regions.toDF('RegionID:int, RegionName:string')\n",
        "regionsdf.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1GToUtN0MZpY",
        "colab": {}
      },
      "source": [
        "territories = sc.textFile('hdfs://localhost:9000/territories')\n",
        "territories = territories.map(lambda x : x.split(',')).map(lambda x : (int(x[0]), x[1], int(x[2])))\n",
        "territoriesdf = territories.toDF('TerritoryID:int, TerritoryName:string, RegionID: int')\n",
        "territoriesdf.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HPkB75FJMZpc"
      },
      "source": [
        "**LAB:** Using the df3 DataFrame, answer the following questions:\n",
        "\n",
        "How many Platinum card purchases were there with a discount above $100?\n",
        "\n",
        "Find the ten biggest discount amounts earned by women and show just the purchase amount, discount, and date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1B9apKoTMZpd",
        "colab": {}
      },
      "source": [
        "print(df3.where(\"CardType = 'Platinum' and Discount > 100\").count())\n",
        "df3.where(\"Gender = 'F'\").orderBy('Amount', ascending = False).select('Amount', 'Discount', 'Date').take(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pzJj7KPoMZpj"
      },
      "source": [
        "**LAB:** Read the Products file from the JSON folder and categories from ths CSVHeaders folder, then join them displaying just the product and category IDs and names, and sort by categoryID then productID. \n",
        "\n",
        "Hint: Drop the ambiguous column after the join."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MRbCDoUMZpl",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "products = spark.read.json('/home/student/ROI/SparkProgram/datasets/northwind/JSON/products')\n",
        "#products.show()\n",
        "products.printSchema()\n",
        "\n",
        "categories = spark.read.csv('/home/student/ROI/SparkProgram/datasets/northwind/CSVHeaders/categories', header = True, inferSchema = True)\n",
        "#categories.show()\n",
        "categories.printSchema()\n",
        "\n",
        "c = categories\n",
        "p = products\n",
        "c.join(p, c.CategoryID == p.categoryid).drop(p.categoryid).select('CategoryID', 'CategoryName', 'productid', 'productname').orderBy('categoryid', 'productid').show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJx2rbFyMZpo",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}